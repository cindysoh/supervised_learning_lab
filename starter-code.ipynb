{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.01 - Supervised Learning Model Comparison\n",
    "\n",
    "Recall the \"data science process.\"\n",
    "\n",
    "1. Define the problem.\n",
    "2. Gather the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. Thus, we'll define the problem and gather the data for you.\n",
    "Most of the questions requiring a written response can be written in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data in order to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that there are certain tax benefits to these accounts. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, check out [this site](https://www.nerdwallet.com/article/ira-vs-401k-retirement-accounts).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "### NOTE: When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. When predicting `e401k`, you may use the entire dataframe if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data.\n",
    "\n",
    "##### 1. Read in the data from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "four01k = pd.read_csv('401ksubs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- education level\n",
    "- empolyment status\n",
    "- number of kids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model in order to better predict who to target when advertising IRAs and 401(k)s. Why would this be an unethical decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This might be seen as discriminating intention. Race should not be a determining factor for targeting audience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we reasonably not use? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- incsq\n",
    "- agesq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs might have done this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- incsq\n",
    "- agesq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9270</th>\n",
       "      <td>0</td>\n",
       "      <td>58.428</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3413.8310</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9271</th>\n",
       "      <td>0</td>\n",
       "      <td>24.546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>602.5061</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>0</td>\n",
       "      <td>38.550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>-13.600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1486.1020</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>0</td>\n",
       "      <td>34.410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>3.550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1184.0480</td>\n",
       "      <td>3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9274</th>\n",
       "      <td>0</td>\n",
       "      <td>25.608</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>655.7697</td>\n",
       "      <td>2401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9275 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0         0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1         1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2         0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3         0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4         0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "...     ...     ...   ...   ...  ...    ...      ...    ...   ...        ...   \n",
       "9270      0  58.428     1     0   33      4   -1.200      0     0  3413.8310   \n",
       "9271      0  24.546     0     1   37      3    2.000      0     0   602.5061   \n",
       "9272      0  38.550     1     0   33      3  -13.600      0     1  1486.1020   \n",
       "9273      0  34.410     1     0   57      3    3.550      0     0  1184.0480   \n",
       "9274      0  25.608     0     1   49      1    1.800      0     0   655.7697   \n",
       "\n",
       "      agesq  \n",
       "0      1600  \n",
       "1      1225  \n",
       "2      1936  \n",
       "3      1936  \n",
       "4      2809  \n",
       "...     ...  \n",
       "9270   1089  \n",
       "9271   1369  \n",
       "9272   1089  \n",
       "9273   3249  \n",
       "9274   2401  \n",
       "\n",
       "[9275 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four01k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Looking at the data dictionary, one variable description appears to be an error. What is this error, and what do you think the correct value would be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- inc variable is describe as income squared: value should be in $1000 representation\n",
    "- age variable is describe as age squared: the values seems to indicate that it should be just age and not squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all modeling tactics we've learned that could be used to solve a regression problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific regression problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Linear Regression: Easy to interpret\n",
    "- Logistic Regression: Not as useful, as it is use for predicting 0 and 1\n",
    "- Polynomial Regression: fit nonlinear models to its data\n",
    "- Ridge Regression: will be benefit if there is a high error due to its variance\n",
    "- Lasso Regression: more effective with narrowing down lots of variables\n",
    "\n",
    "Linear or ridge will be more suitable for predicting income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector regressor\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend setting a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['marr','male','age','fsize','nettfa','incsq','agesq']\n",
    "\n",
    "X = four01k[features]\n",
    "y = four01k['inc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8948254673897011\n",
      "Test score: 0.9055024120733454\n",
      "CV score: 0.8934438475524992\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_sc, y_train)\n",
    "lr_train_score = lr.score(X_train_sc, y_train)\n",
    "lr_test_score = lr.score(X_test_sc, y_test)\n",
    "lr_cv_score = cross_val_score(lr, X_train_sc, y_train, cv=5).mean()\n",
    "print(f\"Train score: {lr_train_score}\")\n",
    "print(f\"Test score: {lr_test_score}\")\n",
    "print(f\"CV score: {lr_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9795704183969427\n",
      "Test score: 0.9728418554699854\n",
      "CV score: 0.9623823509317297\n"
     ]
    }
   ],
   "source": [
    "knnr = KNeighborsRegressor()\n",
    "knnr.fit(X_train_sc, y_train)\n",
    "knnr_train_score = knnr.score(X_train_sc, y_train)\n",
    "knnr_test_score = knnr.score(X_test_sc, y_test)\n",
    "knnr_cv_score = cross_val_score(knnr, X_train_sc, y_train, cv=5).mean()\n",
    "print(f\"Train score: {knnr_train_score}\")\n",
    "print(f\"Test score: {knnr_test_score}\")\n",
    "print(f\"CV score: {knnr_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "Test score: 0.9999909563973628\n",
      "CV score: 0.9998272867504279\n"
     ]
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(X_train_sc, y_train)\n",
    "dtr_train_score = dtr.score(X_train_sc, y_train)\n",
    "dtr_test_score = dtr.score(X_test_sc, y_test)\n",
    "dtr_cv_score = cross_val_score(dtr, X_train_sc, y_train, cv=5).mean()\n",
    "print(f\"Train score: {dtr_train_score}\")\n",
    "print(f\"Test score: {dtr_test_score}\")\n",
    "print(f\"CV score: {dtr_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9999757732345468\n",
      "Test score: 0.9999631663709371\n",
      "CV score: 0.9999055466797975\n"
     ]
    }
   ],
   "source": [
    "bagr = BaggingRegressor()\n",
    "bagr.fit(X_train_sc, y_train)\n",
    "bagr_train_score = bagr.score(X_train_sc, y_train)\n",
    "bagr_test_score = bagr.score(X_test_sc, y_test)\n",
    "bagr_cv_score = cross_val_score(bagr, X_train_sc, y_train, cv=5).mean()\n",
    "print(f\"Train score: {bagr_train_score}\")\n",
    "print(f\"Test score: {bagr_test_score}\")\n",
    "print(f\"CV score: {bagr_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9999898735621409\n",
      "Test score: 0.9999898936278704\n",
      "CV score: 0.9999308283139303\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train_sc, y_train)\n",
    "rfr_train_score = rfr.score(X_train_sc, y_train)\n",
    "rfr_test_score = rfr.score(X_test_sc, y_test)\n",
    "rfr_cv_score = cross_val_score(rfr, X_train_sc, y_train, cv=5).mean()\n",
    "print(f\"Train score: {rfr_train_score}\")\n",
    "print(f\"Test score: {rfr_test_score}\")\n",
    "print(f\"CV score: {rfr_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9912628361100356\n",
      "Test score: 0.9915051491315466\n",
      "CV score: 0.990853851781061\n"
     ]
    }
   ],
   "source": [
    "adar = AdaBoostRegressor()\n",
    "adar.fit(X_train_sc, y_train)\n",
    "adar_train_score = adar.score(X_train_sc, y_train)\n",
    "adar_test_score = adar.score(X_test_sc, y_test)\n",
    "adar_cv_score = cross_val_score(adar, X_train_sc, y_train, cv=5).mean()\n",
    "print(f\"Train score: {adar_train_score}\")\n",
    "print(f\"Test score: {adar_test_score}\")\n",
    "print(f\"CV score: {adar_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8838451674009064\n",
      "Test score: 0.8796790700988567\n",
      "CV score: 0.8679108667118862\n"
     ]
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr.fit(X_train_sc, y_train)\n",
    "svr_train_score = svr.score(X_train_sc, y_train)\n",
    "svr_test_score = svr.score(X_test_sc, y_test)\n",
    "svr_cv_score = cross_val_score(svr, X_train_sc, y_train, cv=5).mean()\n",
    "print(f\"Train score: {svr_train_score}\")\n",
    "print(f\"Test score: {svr_test_score}\")\n",
    "print(f\"CV score: {svr_cv_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping is random resampling with replacement. The sample is only relying on smaller samples of itself to make calculations on, in order to draw conclusions for the larger population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees have some limitations. Trees that are grown very deep tend to learn highly irregular patterns(thus overfitting).\n",
    "\n",
    "Bagging (bootstrap aggregating) mitigates this problem by exposing different trees to different sub-samples of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific and precise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging is an ensemble algorithm that fits multiple models on different subsets of a training dataset, then combines the predictions from all models. Random forest is an extension of bagging that also randomly selects subsets of features used in each data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is a classification algorithm consisting of many decision trees combined to get a more accurate result as compared to a single tree. Random forest algorithm avoids and prevents overfitting by using multiple trees. This gives accurate and precise results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 7.77621651619324\n",
      "Test RMSE: 7.506111330932505\n"
     ]
    }
   ],
   "source": [
    "lr_y_pred_train = lr.predict(X_train_sc)\n",
    "lr_y_pred_test = lr.predict(X_test_sc)\n",
    "lr_rmse_train = np.sqrt(metrics.mean_squared_error(y_train, lr_y_pred_train))\n",
    "lr_rmse_test = np.sqrt(metrics.mean_squared_error(y_test, lr_y_pred_test))\n",
    "print(f\"Train RMSE: {lr_rmse_train}\")\n",
    "print(f\"Test RMSE: {lr_rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 3.4272263258974696\n",
      "Test RMSE: 4.02396956785657\n"
     ]
    }
   ],
   "source": [
    "knnr_y_pred_train = knnr.predict(X_train_sc)\n",
    "knnr_y_pred_test = knnr.predict(X_test_sc)\n",
    "knnr_rmse_train = np.sqrt(metrics.mean_squared_error(y_train, knnr_y_pred_train))\n",
    "knnr_rmse_test = np.sqrt(metrics.mean_squared_error(y_test, knnr_y_pred_test))\n",
    "print(f\"Train RMSE: {knnr_rmse_train}\")\n",
    "print(f\"Test RMSE: {knnr_rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 5.379733536431154e-16\n",
      "Test RMSE: 0.15028649799328536\n"
     ]
    }
   ],
   "source": [
    "dtr_y_pred_train = dtr.predict(X_train_sc)\n",
    "dtr_y_pred_test = dtr.predict(X_test_sc)\n",
    "dtr_rmse_train = np.sqrt(metrics.mean_squared_error(y_train, dtr_y_pred_train))\n",
    "dtr_rmse_test = np.sqrt(metrics.mean_squared_error(y_test, dtr_y_pred_test))\n",
    "print(f\"Train RMSE: {dtr_rmse_train}\")\n",
    "print(f\"Test RMSE: {dtr_rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.11161614549308091\n",
      "Test RMSE: 0.08438828258729786\n"
     ]
    }
   ],
   "source": [
    "bagr_y_pred_train = bagr.predict(X_train_sc)\n",
    "bagr_y_pred_test = bagr.predict(X_test_sc)\n",
    "bagr_rmse_train = np.sqrt(metrics.mean_squared_error(y_train, bagr_y_pred_train))\n",
    "bagr_rmse_test = np.sqrt(metrics.mean_squared_error(y_test, bagr_y_pred_test))\n",
    "print(f\"Train RMSE: {bagr_rmse_train}\")\n",
    "print(f\"Test RMSE: {bagr_rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.07579454044767023\n",
      "Test RMSE: 0.07556073403552105\n"
     ]
    }
   ],
   "source": [
    "rfr_y_pred_train = rfr.predict(X_train_sc)\n",
    "rfr_y_pred_test = rfr.predict(X_test_sc)\n",
    "rfr_rmse_train = np.sqrt(metrics.mean_squared_error(y_train, rfr_y_pred_train))\n",
    "rfr_rmse_test = np.sqrt(metrics.mean_squared_error(y_test, rfr_y_pred_test))\n",
    "print(f\"Train RMSE: {rfr_rmse_train}\")\n",
    "print(f\"Test RMSE: {rfr_rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 2.1805111767184973\n",
      "Test RMSE: 2.1711311236749933\n"
     ]
    }
   ],
   "source": [
    "adar_y_pred_train = adar.predict(X_train_sc)\n",
    "adar_y_pred_test = adar.predict(X_test_sc)\n",
    "adar_rmse_train = np.sqrt(metrics.mean_squared_error(y_train, adar_y_pred_train))\n",
    "adar_rmse_test = np.sqrt(metrics.mean_squared_error(y_test, adar_y_pred_test))\n",
    "print(f\"Train RMSE: {adar_rmse_train}\")\n",
    "print(f\"Test RMSE: {adar_rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 8.17206270928853\n",
      "Test RMSE: 8.469840458655094\n"
     ]
    }
   ],
   "source": [
    "svr_y_pred_train = svr.predict(X_train_sc)\n",
    "svr_y_pred_test = svr.predict(X_test_sc)\n",
    "svr_rmse_train = np.sqrt(metrics.mean_squared_error(y_train, svr_y_pred_train))\n",
    "svr_rmse_test = np.sqrt(metrics.mean_squared_error(y_test, svr_y_pred_test))\n",
    "print(f\"Train RMSE: {svr_rmse_train}\")\n",
    "print(f\"Test RMSE: {svr_rmse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Based on training RMSE and testing RMSE, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearRegression, KNeighborsRegressor, BaggingRegressor, AdaBoostRegressor, support vector regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest regressor as it has the smallest RMSE and least variance between train RMSE and test RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search for the best param for the following: max_depth, min_samples_split, min_weight_fraction_leaf, min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e401k and p401k will probably have similar/overlapping results, thus it shouldn't be used to predict e401k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all modeling tactics we've learned that could be used to solve a classification problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific classification problem and explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression: when the classification problem is binary — true or false\n",
    "- Decision Tree: branches in a hierarchy approach and each branch can be considered as an if-else statement\n",
    "- Random Forest: collection of decision trees. aggregate results from multiple predictors\n",
    "- Support Vector Machine (SVM): classify the data based on the position in relation to a border between positive class and negative class\n",
    "- K-Nearest Neighbour (KNN): calculates the distance between one point to another, then assign the label of unobserved data based on the labels of nearest observed data points\n",
    "- Naive Bayes: naive assumption that each feature is independent to each other. performs relatively well even when the training data size is small\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector classifier\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, plot_roc_curve, roc_auc_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = four01k.drop(['e401k','p401k'], axis=1)\n",
    "y2 = four01k['e401k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X2_train_sc = ss.fit_transform(X2_train)\n",
    "X2_test_sc = ss.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.6569867740080506\n",
      "Test score: 0.6550237171194481\n",
      "CV score: 0.6546859118966756\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X2_train_sc, y2_train)\n",
    "logreg_train_score = logreg.score(X2_train_sc, y2_train)\n",
    "logreg_test_score = logreg.score(X2_test_sc, y2_test)\n",
    "logreg_cv_score = cross_val_score(logreg, X2_train_sc, y2_train, cv=5).mean()\n",
    "print(f\"Train score: {logreg_train_score}\")\n",
    "print(f\"Test score: {logreg_test_score}\")\n",
    "print(f\"CV score: {logreg_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindy/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg_preds = logreg.predict(X2_test_sc)\n",
    "logreg_matrix = confusion_matrix(y2_test, logreg_preds)\n",
    "tn, fp, fn, tp = logreg_matrix.ravel()\n",
    "plot_confusion_matrix(logreg, X2_test_sc, y2_test, cmap='Blues', \n",
    "                      values_format='d', display_labels=[1,0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7515813686026452\n",
      "Test score: 0.6399310047434239\n",
      "CV score: 0.6213324367650825\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X2_train_sc, y2_train)\n",
    "knn_train_score = knn.score(X2_train_sc, y2_train)\n",
    "knn_test_score = knn.score(X2_test_sc, y2_test)\n",
    "knn_cv_score = cross_val_score(knn, X2_train_sc, y2_train, cv=5).mean()\n",
    "print(f\"Train score: {knn_train_score}\")\n",
    "print(f\"Test score: {knn_test_score}\")\n",
    "print(f\"CV score: {knn_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cindy/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_preds = knn.predict(X2_test_sc)\n",
    "knn_matrix = confusion_matrix(y2_test, knn_preds)\n",
    "tn2, fp2, fn2, tp2 = knn_matrix.ravel()\n",
    "plot_confusion_matrix(knn, X2_test_sc, y2_test, cmap='Blues', \n",
    "                      values_format='d', display_labels=[1,0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6399310047434239"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y2_test, knn_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7510548523206751"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec = tn2 / (tn2 + fp2)\n",
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.463768115942029"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y2_test, knn_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5402597402597402"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y2_test, knn_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "Test score: 0.5821474773609314\n",
      "CV score: 0.5977578563342341\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X2_train_sc, y2_train)\n",
    "dt_train_score = dt.score(X2_train_sc, y2_train)\n",
    "dt_test_score = dt.score(X2_test_sc, y2_test)\n",
    "dt_cv_score = cross_val_score(dt, X2_train_sc, y2_train, cv=5).mean()\n",
    "print(f\"Train score: {dt_train_score}\")\n",
    "print(f\"Test score: {dt_test_score}\")\n",
    "print(f\"CV score: {dt_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9752731454859115\n",
      "Test score: 0.6515739542906425\n",
      "CV score: 0.6473542973301271\n"
     ]
    }
   ],
   "source": [
    "bag = BaggingClassifier()\n",
    "bag.fit(X2_train_sc, y2_train)\n",
    "bag_train_score = bag.score(X2_train_sc, y2_train)\n",
    "bag_test_score = bag.score(X2_test_sc, y2_test)\n",
    "bag_cv_score = cross_val_score(bag, X2_train_sc, y2_train, cv=5).mean()\n",
    "print(f\"Train score: {bag_train_score}\")\n",
    "print(f\"Test score: {bag_test_score}\")\n",
    "print(f\"CV score: {bag_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.0\n",
      "Test score: 0.6670978870202674\n",
      "CV score: 0.6631680879545849\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X2_train_sc, y2_train)\n",
    "rf_train_score = rf.score(X2_train_sc, y2_train)\n",
    "rf_test_score = rf.score(X2_test_sc, y2_test)\n",
    "rf_cv_score = cross_val_score(rf, X2_train_sc, y2_train, cv=5).mean()\n",
    "print(f\"Train score: {rf_train_score}\")\n",
    "print(f\"Test score: {rf_test_score}\")\n",
    "print(f\"CV score: {rf_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.6927832087406556\n",
      "Test score: 0.685640362225097\n",
      "CV score: 0.6795571076790864\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X2_train_sc, y2_train)\n",
    "ada_train_score = ada.score(X2_train_sc, y2_train)\n",
    "ada_test_score = ada.score(X2_test_sc, y2_test)\n",
    "ada_cv_score = cross_val_score(ada, X2_train_sc, y2_train, cv=5).mean()\n",
    "print(f\"Train score: {ada_train_score}\")\n",
    "print(f\"Test score: {ada_test_score}\")\n",
    "print(f\"CV score: {ada_cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.683870040253019\n",
      "Test score: 0.6774471755066839\n",
      "CV score: 0.665324913028748\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X2_train_sc, y2_train)\n",
    "svm_train_score = svm.score(X2_train_sc, y2_train)\n",
    "svm_test_score = svm.score(X2_test_sc, y2_test)\n",
    "svm_cv_score = cross_val_score(svm, X2_train_sc, y2_train, cv=5).mean()\n",
    "print(f\"Train score: {svm_train_score}\")\n",
    "print(f\"Test score: {svm_test_score}\")\n",
    "print(f\"CV score: {svm_cv_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- false positives: predicted eligible but is not\n",
    "- false negatives: predicted as not eligible but is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minimize false positive. More false negative has lesser risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is calculated from the precision and recall of the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Train: 0.4822048611111111\n",
      "F1 Test: 0.4708994708994709\n"
     ]
    }
   ],
   "source": [
    "logreg_preds_train = logreg.predict(X2_train_sc)\n",
    "logreg_f1_train = f1_score(y2_train, logreg_preds_train)\n",
    "print(f'F1 Train: {logreg_f1_train}')\n",
    "\n",
    "logreg_preds_test = logreg.predict(X2_test_sc)\n",
    "logreg_f1_test = f1_score(y2_test, logreg_preds_test)\n",
    "print(f'F1 Test: {logreg_f1_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Train: 0.6587677725118484\n",
      "F1 Train: 0.49910017996400713\n"
     ]
    }
   ],
   "source": [
    "knn_preds_train = knn.predict(X2_train_sc)\n",
    "knn_f1_train = f1_score(y2_train, knn_preds_train)\n",
    "print(f'F1 Train: {knn_f1_train}')\n",
    "\n",
    "knn_preds_test = knn.predict(X2_test_sc)\n",
    "knn_f1_test = f1_score(y2_test, knn_preds_test)\n",
    "print(f'F1 Train: {knn_f1_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Train: 1.0\n",
      "F1 Train: 0.47020229633679606\n"
     ]
    }
   ],
   "source": [
    "dt_preds_train = dt.predict(X2_train_sc)\n",
    "dt_f1_train = f1_score(y2_train, dt_preds_train)\n",
    "print(f'F1 Train: {dt_f1_train}')\n",
    "\n",
    "dt_preds_test = dt.predict(X2_test_sc)\n",
    "dt_f1_test = f1_score(y2_test, dt_preds_test)\n",
    "print(f'F1 Train: {dt_f1_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Train: 0.9678504672897196\n",
      "F1 Train: 0.4987593052109181\n"
     ]
    }
   ],
   "source": [
    "bag_preds_train = bag.predict(X2_train_sc)\n",
    "bag_f1_train = f1_score(y2_train, bag_preds_train)\n",
    "print(f'F1 Train: {bag_f1_train}')\n",
    "\n",
    "bag_preds_test = bag.predict(X2_test_sc)\n",
    "bag_f1_test = f1_score(y2_test, bag_preds_test)\n",
    "print(f'F1 Train: {bag_f1_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Train: 1.0\n",
      "F1 Train: 0.5326876513317191\n"
     ]
    }
   ],
   "source": [
    "rf_preds_train = rf.predict(X2_train_sc)\n",
    "rf_f1_train = f1_score(y2_train, rf_preds_train)\n",
    "print(f'F1 Train: {rf_f1_train}')\n",
    "\n",
    "rf_preds_test = rf.predict(X2_test_sc)\n",
    "rf_f1_test = f1_score(y2_test, rf_preds_test)\n",
    "print(f'F1 Train: {rf_f1_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Train: 0.569066344020972\n",
      "F1 Train: 0.5552165954850519\n"
     ]
    }
   ],
   "source": [
    "ada_preds_train = ada.predict(X2_train_sc)\n",
    "ada_f1_train = f1_score(y2_train, ada_preds_train)\n",
    "print(f'F1 Train: {ada_f1_train}')\n",
    "\n",
    "ada_preds_test = ada.predict(X2_test_sc)\n",
    "ada_f1_test = f1_score(y2_test, ada_preds_test)\n",
    "print(f'F1 Train: {ada_f1_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Train: 0.4805102763997165\n",
      "F1 Train: 0.46031746031746035\n"
     ]
    }
   ],
   "source": [
    "svm_preds_train = svm.predict(X2_train_sc)\n",
    "svm_f1_train = f1_score(y2_train, svm_preds_train)\n",
    "print(f'F1 Train: {svm_f1_train}')\n",
    "\n",
    "svm_preds_test = svm.predict(X2_test_sc)\n",
    "svm_f1_test = f1_score(y2_test, svm_preds_test)\n",
    "print(f'F1 Train: {svm_f1_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier, DecisionTreeClassifier, BaggingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search for the best param for the following: n_estimators, learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Answer the problem.\n",
    "\n",
    "##### BONUS: Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
